{
    "dataset": {
        "dir": "input/data-science-bowl-2019/",
        "feature_dir": "features",
        "params": null
    },
    "av": {
        "params": {},
        "split_params": {
            "n_splits": 5,
            "random_state": 42
        },
        "model_params": {
            "objective": "binary",
            "metric": "auc",
            "boosting": "gbdt",
            "max_depth": 7,
            "num_leaves": 75,
            "learning_rate": 0.01,
            "colsample_bytree": 0.7,
            "subsample": 0.1,
            "subsample_freq": 1,
            "seed": 111,
            "feature_fraction_seed": 111,
            "drop_seed": 111,
            "verbose": -1,
            "n_jobs": -1,
            "first_metric_only": true
        },
        "train_params": {
            "num_boost_round": 50000,
            "early_stopping_rounds": 200,
            "verbose_eval": 200
        }
    },
    "model": {
        "name": "nn",
        "sampling": {
            "name": "none",
            "params": {}
        },
        "model_params": {
            "emb_drop": 0.3,
            "drop": 0.5
        },
        "train_params": {
            "scheduler": {
                "name": "cosine",
                "T_max": 10,
                "eta_min": 1e-05
            },
            "batch_size": 256,
            "n_epochs": 50,
            "lr": 0.001
        },
        "mode": "ovr",
        "save_path": "output/nn_9_ovr_0.95_reduction/pth/",
        "policy": "best_score"
    },
    "post_process": {
        "params": {
            "reverse": false,
            "n_overall": 20,
            "n_classwise": 20
        }
    },
    "val": {
        "name": "group_kfold",
        "params": {
            "n_splits": 5,
            "random_state": 111
        },
        "n_delete": 0.95
    },
    "output_dir": "output",
    "features": [
        "PastSummary3",
        "NakamaV8"
    ],
    "args": {
        "config": "config/nn_9_ovr_0.95_reduction.yml"
    },
    "model_output_dir": "output/nn_9_ovr_0.95_reduction",
    "av_result": {
        "score": {
            "fold0": {
                "train": {
                    "auc": 0.8133600277830316
                },
                "valid": {
                    "auc": 0.5214999466788908
                }
            },
            "fold1": {
                "train": {
                    "auc": 0.7130761789227372
                },
                "valid": {
                    "auc": 0.5969492862981638
                }
            },
            "fold2": {
                "train": {
                    "auc": 0.7510484000376266
                },
                "valid": {
                    "auc": 0.5274029718786734
                }
            },
            "fold3": {
                "train": {
                    "auc": 0.6848564654056827
                },
                "valid": {
                    "auc": 0.5574729204479798
                }
            },
            "fold4": {
                "train": {
                    "auc": 0.9404856196341628
                },
                "valid": {
                    "auc": 0.5584443138312529
                }
            }
        },
        "feature_importances": {
            "nunique_event_count": 1092.7132428712137,
            "Ratio_4070_Counter": 865.6531610842105,
            "Ratio_2030_Counter": 838.1174146789934,
            "Ratio_4020_Counter": 744.669851349503,
            "Ratio_4025_Counter": 743.3076690965455,
            "4070": 690.2731693498623,
            "Ratio_Game_Counter": 657.90969776862,
            "mean_action_time_All Star Sorting": 635.6542506480961,
            "Ratio_3021_Counter": 602.7099544739028,
            "mean_action_time_Happy Camel": 599.4945336226583,
            "Ratio_3121_Counter": 577.9580739826206,
            "Ratio_4090_Counter": 576.5658865691353,
            "mean_action_time_Scrub-A-Dub": 556.6931331982678,
            "Ratio_3020_Counter": 524.5023225659165,
            "Chow Time_4070": 521.2576307924608,
            "mean_target": 516.0495834287593,
            "Ratio_Sandcastle_Builder__Activity__4020_Counter": 468.711064269891,
            "Ratio_2010_Counter": 458.42583495140354,
            "Cauldron Filler (Assessment)_mean_action_time": 453.16524038332886,
            "Ratio_Crystal_Caves___Level_3_2000_Counter": 448.1177341401667,
            "Ratio_3120_Counter": 404.2159572740076,
            "2000": 373.9265938018837,
            "27253bdc": 373.694587265111,
            "success_ratio_Scrub-A-Dub": 352.74991657551146,
            "mean_correct_Chow Time": 292.5146464258756,
            "Chest Sorter (Assessment)_mean_action_time": 286.0773043282019,
            "total_accuracy": 284.6911790981682,
            "Chest Sorter (Assessment)_mean_var_action_time": 269.6553473896009,
            "total_accuracy_7day_Bird_Measurer__Assessment_": 257.0632480487533,
            "accuracy_group_mean": 250.41932207001537,
            "mean_incorrect_All Star Sorting": 244.4596485712551,
            "accuracy_group_mean_7day": 242.91955652962204,
            "success_ratio_Happy Camel": 238.5372681334371,
            "Mushroom Sorter (Assessment)_success_ratio": 225.06491714677296,
            "accumulated_acc": 224.0307051183927,
            "mean_incorrect_Pan Balance": 217.62368136607802,
            "Clip_Counter": 205.95674660171179,
            "total_accuracy_7day": 202.38081097653668,
            "Ratio_Chest_Sorter__Assessment__4020_Counter": 195.33562055103175,
            "num_correct_mean": 191.28148713911432,
            "total_accuracy_7day_Mushroom_Sorter__Assessment_": 191.1496068953489,
            "Ratio_Chest_Sorter__Assessment__4025_Counter": 186.48477192882464,
            "accumulated_accuracy_group": 182.1196960512967,
            "Cauldron Filler (Assessment)_3020_mean": 165.49122723956063,
            "total_accuracy_Chest_Sorter__Assessment_": 145.01411158672627,
            "var_action_time_Scrub-A-Dub": 144.56647856482982,
            "mean_correct_Leaf Leader": 140.42726427826946,
            "last_success_ratio_Crystals Rule": 136.32572776847974,
            "session_title": 126.31970500036368,
            "num_incorrect_title_mean": 114.7922318392527,
            "success_ratio_Pan Balance": 113.34121162539515,
            "Mushroom Sorter (Assessment)_accuracy_group": 111.96414001404736,
            "accuracy_group_median": 98.48394548994838,
            "mean_timte_to_get_success_same_assess": 85.32578004238638,
            "decayed_accuracy_group_last_same_assess": 82.85624616490395,
            "world": 78.01371319891405,
            "last_success_ratio_Pan Balance": 75.71387867807285,
            "Crystal Caves - Level 3_2000": 74.56140486973209,
            "Crystal_Caves___Level_3_2000_Counter": 67.35111224068096,
            "title": 61.89571031735977,
            "accuracy_group_title_mean": 56.407210560720884,
            "decayed_success_ratio_last_same_assess": 56.343991893919885,
            "success_ratio_same_assess": 56.039567326679595,
            "accuracy_group_title_7day_last": 35.71584353480139,
            "num_incorrect_title_median": 26.40493652875098,
            "mean_accuracy_group_same_assess": 19.850524638913342,
            "accuracy_group_title_last": 18.200241484584332,
            "num_correct_title_mean": 17.90165827226374,
            "success_ratio_last_same_assess": 16.29984510038048,
            "accuracy_group_title_median": 12.85075954345084,
            "num_correct_title_last": 1.5483519554138183
        }
    },
    "eval_results": {
        "evals_result": {
            "oof_score": 0.5919812420303067,
            "normal_oof_score": 0.6044927027179059,
            "truncated_eval_mean": 0.5608005745592833,
            "truncated_eval_0.95upper": 0.5790276173766894,
            "truncated_eval_0.95lower": 0.5425735317418773,
            "truncated_eval_std": 0.009113521408703041,
            "cv_score": {
                "cv1": {
                    "loss": 0.4078321506579717,
                    "qwk": 0.6272518114731406
                },
                "cv2": {
                    "loss": 0.42635192970434826,
                    "qwk": 0.5875016171317929
                },
                "cv3": {
                    "loss": 0.41399523119131726,
                    "qwk": 0.5923920552239768
                },
                "cv4": {
                    "loss": 0.4211180110772451,
                    "qwk": 0.5961487139604995
                },
                "cv5": {
                    "loss": 0.4189404845237732,
                    "qwk": 0.5895778466245116
                }
            },
            "n_data": 17690,
            "n_features": 71
        },
        "feature_importance": {
            "title": 0.5763589905146023,
            "total_accuracy_Chest_Sorter__Assessment_": 0.5450253764383752,
            "total_accuracy_7day_Mushroom_Sorter__Assessment_": 0.5445005492630687,
            "total_accuracy_7day_Bird_Measurer__Assessment_": 0.5406740550843001,
            "total_accuracy": 0.533552016930499,
            "total_accuracy_7day": 0.5324269252383904,
            "num_incorrect_title_median": 0.5323991737972856,
            "nunique_event_count": 0.5319852585882375,
            "num_incorrect_title_mean": 0.5203266788308876,
            "num_correct_title_mean": 0.5084009423549108,
            "num_correct_title_last": 0.4880665041387802,
            "accuracy_group_title_median": 0.4704159571219567,
            "num_correct_mean": 0.46930287933764764,
            "accuracy_group_title_last": 0.4675611825529525,
            "accuracy_group_title_mean": 0.4668572896438613,
            "accuracy_group_title_7day_last": 0.4656404626255372,
            "accuracy_group_mean": 0.4549681864812013,
            "accuracy_group_median": 0.4538056458914502,
            "Ratio_Sandcastle_Builder__Activity__4020_Counter": 0.4536343150068081,
            "accuracy_group_mean_7day": 0.45211298194473004,
            "Ratio_Crystal_Caves___Level_3_2000_Counter": 0.4451121334531337,
            "Ratio_Game_Counter": 0.4448361277540954,
            "Ratio_Chest_Sorter__Assessment__4025_Counter": 0.44032511315180667,
            "Ratio_4090_Counter": 0.4383752006739618,
            "Ratio_Chest_Sorter__Assessment__4020_Counter": 0.4383341465023946,
            "Ratio_4070_Counter": 0.43468453259447326,
            "Ratio_4020_Counter": 0.41793166667950776,
            "Ratio_4025_Counter": 0.4156213341952821,
            "Ratio_3121_Counter": 0.4082489401563979,
            "Ratio_3120_Counter": 0.4008994861611136,
            "Ratio_3021_Counter": 0.3949588861353836,
            "Ratio_3020_Counter": 0.390355843351953,
            "Ratio_2030_Counter": 0.37888673413059265,
            "Crystal_Caves___Level_3_2000_Counter": 0.3763013007903169,
            "Ratio_2010_Counter": 0.3755761575819109,
            "Clip_Counter": 0.37005045431139116,
            "mean_target": 0.36284152104683554,
            "Mushroom Sorter (Assessment)_success_ratio": 0.07305350848168338,
            "var_action_time_Scrub-A-Dub": 0.06927942227132536,
            "mean_action_time_Scrub-A-Dub": 0.06535370698573159,
            "success_ratio_Scrub-A-Dub": 0.06426750485760399,
            "last_success_ratio_Pan Balance": 0.0629366040731971,
            "mean_incorrect_Pan Balance": 0.06060534455258855,
            "success_ratio_Pan Balance": 0.060570043944876306,
            "mean_correct_Leaf Leader": 0.05726367109922057,
            "mean_action_time_Happy Camel": 0.05472199402980029,
            "success_ratio_Happy Camel": 0.053833844099726955,
            "last_success_ratio_Crystals Rule": 0.047385239499022555,
            "mean_correct_Chow Time": 0.0455223797669418,
            "mean_incorrect_All Star Sorting": 0.04398287905483746,
            "mean_action_time_All Star Sorting": 0.04271690393233638,
            "Chest Sorter (Assessment)_mean_var_action_time": 0.03792161240488641,
            "Chest Sorter (Assessment)_mean_action_time": 0.03787197759863481,
            "Cauldron Filler (Assessment)_3020_mean": 0.03724401981211507,
            "Cauldron Filler (Assessment)_mean_action_time": 0.03035342845547091,
            "decayed_success_ratio_last_same_assess": 0.029461602348843853,
            "decayed_accuracy_group_last_same_assess": 0.028401341849110896,
            "world": 0.028120401045354737,
            "Mushroom Sorter (Assessment)_accuracy_group": 0.027544115159814586,
            "success_ratio_same_assess": 0.027159342753702354,
            "mean_accuracy_group_same_assess": 0.026980474724657345,
            "mean_timte_to_get_success_same_assess": 0.026523893003595367,
            "accumulated_accuracy_group": 0.026229430476695615,
            "success_ratio_last_same_assess": 0.025891915621960426,
            "accumulated_acc": 0.025187631077875406,
            "session_title": 0.024183840078249565,
            "Chow Time_4070": 0.020215242305657875,
            "Crystal Caves - Level 3_2000": 0.018627935116724892,
            "27253bdc": 0.01776385713790125,
            "4070": 0.010351893133173418,
            "2000": 0.006169325943660797
        }
    },
    "truncated_mean_adjust": 0.5687646868807297,
    "truncated_std_adjust": 0.023248422214662536,
    "truncated_upper": 0.6152615313100548,
    "truncated_lower": 0.5222678424514046
}