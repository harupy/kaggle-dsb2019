{
    "dataset": {
        "dir": "input/data-science-bowl-2019/",
        "feature_dir": "features",
        "params": null
    },
    "av": {
        "params": {},
        "split_params": {
            "n_splits": 5,
            "random_state": 42
        },
        "model_params": {
            "objective": "binary",
            "metric": "auc",
            "boosting": "gbdt",
            "max_depth": 7,
            "num_leaves": 75,
            "learning_rate": 0.01,
            "colsample_bytree": 0.7,
            "subsample": 0.1,
            "subsample_freq": 1,
            "seed": 111,
            "feature_fraction_seed": 111,
            "drop_seed": 111,
            "verbose": -1,
            "n_jobs": -1,
            "first_metric_only": true
        },
        "train_params": {
            "num_boost_round": 50000,
            "early_stopping_rounds": 200,
            "verbose_eval": 200
        }
    },
    "model": {
        "name": "lgbm",
        "sampling": {
            "name": "none",
            "params": {
                "k_neighbors": 7,
                "n_jobs": 4,
                "random_state": 42,
                "acc_0_coef": 1.0,
                "acc_1_coef": 1.0,
                "acc_2_coef": 1.0,
                "acc_3_coef": 1.0
            }
        },
        "model_params": {
            "objective": "multiclass",
            "num_class": 4,
            "boosting_type": "gbdt",
            "max_depth": 6,
            "num_leaves": 25,
            "tree_learner": "serial",
            "learning_rate": 0.01,
            "subsample": 0.8,
            "subsample_freq": 1,
            "colsample_bytree": 0.7,
            "data_random_seed": 71,
            "seed": 71,
            "bagging_seed": 71,
            "feature_fraction_seed": 71,
            "drop_seed": 71,
            "reg_alpha": 0.1,
            "min_split_gain": 0.5,
            "reg_lambda": 0.1,
            "min_data_in_leaf": 100,
            "verbose": -1,
            "n_jobs": -1,
            "first_metric_only": true
        },
        "train_params": {
            "num_boost_round": 10000,
            "early_stopping_rounds": 100,
            "verbose_eval": 100
        },
        "mode": "multiclass"
    },
    "post_process": {
        "params": {
            "reverse": false,
            "n_overall": 20,
            "n_classwise": 20
        }
    },
    "val": {
        "name": "group_kfold",
        "params": {
            "n_splits": 5,
            "random_state": 111
        },
        "n_delete": 0.6
    },
    "output_dir": "output",
    "features": [
        "PastSummary3"
    ],
    "args": {
        "config": "config/lgb_30_PastSummary3_selection.yml"
    },
    "model_output_dir": "output/lgb_30_PastSummary3_selection",
    "av_result": {
        "score": {
            "fold0": {
                "train": {
                    "auc": 0.6163438428598254
                },
                "valid": {
                    "auc": 0.5421793849449837
                }
            },
            "fold1": {
                "train": {
                    "auc": 0.7472723194647996
                },
                "valid": {
                    "auc": 0.5833856131231395
                }
            },
            "fold2": {
                "train": {
                    "auc": 0.8663345561992662
                },
                "valid": {
                    "auc": 0.5364033369167345
                }
            },
            "fold3": {
                "train": {
                    "auc": 0.8918814626531022
                },
                "valid": {
                    "auc": 0.594517266132468
                }
            },
            "fold4": {
                "train": {
                    "auc": 0.8732072167837206
                },
                "valid": {
                    "auc": 0.6032719581620868
                }
            }
        },
        "feature_importances": {
            "duration_mean": 357.21446232423693,
            "4035": 304.81097104175933,
            "mean_action_time_Scrub-A-Dub": 294.72844709189195,
            "mean_action_time_Chow Time": 279.0884106794489,
            "mean_4070_All Star Sorting": 264.3473046475468,
            "Bug Measurer (Activity)_duration": 258.98725630143525,
            "4070": 258.0138092078393,
            "count_4070_All Star Sorting": 257.7929731415881,
            "3110": 248.3097850839752,
            "mean_action_time_Dino Drink": 244.24518463849054,
            "Cauldron Filler (Assessment)_mean_var_action_time": 241.65929168182703,
            "success_ratio_Chow Time": 240.2066401735268,
            "Chow Time_4070": 235.65873191641163,
            "Bird Measurer (Assessment)_4020": 232.35136671420477,
            "mean_action_time_Happy Camel": 231.2272634378974,
            "Sandcastle Builder (Activity)_4070": 221.17198070085607,
            "4030": 214.2997398478361,
            "4090": 210.83730666652474,
            "mean_incorrect_Scrub-A-Dub": 210.49578787019368,
            "Cauldron Filler (Assessment)_mean_action_time": 208.39263000284154,
            "Mushroom Sorter (Assessment)_mean_action_time": 202.94847054655366,
            "launched_ratio": 202.73822228890486,
            "Bug Measurer (Activity)_4035": 197.71438849792804,
            "4020": 194.28919398165982,
            "3121": 188.898304552686,
            "mean_action_time_All Star Sorting": 188.10800725117764,
            "27253bdc": 187.67994219029296,
            "mean_target": 186.27041617991233,
            "3120": 185.7222588294224,
            "Bird Measurer (Assessment)_mean_var_action_time": 183.34860972337555,
            "Chest Sorter (Assessment)_mean_var_action_time": 177.27917196556132,
            "Sandcastle Builder (Activity)_4020": 175.77509465071964,
            "success_ratio_Dino Dive": 173.54842720593547,
            "Mushroom Sorter (Assessment)_mean_var_action_time": 170.01226278056046,
            "n_launched_False": 164.83518316515693,
            "Sandcastle Builder (Activity)_duration": 162.57443314968828,
            "memory_decay_coeff_from_last_assess": 153.69381967676782,
            "sand_filled_ratio": 145.05295662262725,
            "Cart Balancer (Assessment)_4070_mean": 143.72525090285652,
            "4022": 142.8956168210148,
            "success_ratio_All Star Sorting": 141.29376812446935,
            "mean_incorrect_Chow Time": 138.47842843953512,
            "Chest Sorter (Assessment)_mean_action_time": 136.27139922919923,
            "Bird Measurer (Assessment)_success_ratio": 136.11647207867355,
            "2000": 135.7082333399415,
            "last_success_ratio_Chow Time": 133.58001249088957,
            "Cart Balancer (Assessment)_4070": 128.8366187580262,
            "Crystal Caves - Level 2_2000": 128.66063596794265,
            "accumulated_acc": 126.45264441430918,
            "Mushroom Sorter (Assessment)_4070": 123.6602475022043,
            "Mushroom Sorter (Assessment)_var_mean_action_time": 123.24953454508463,
            "last_success_ratio_Scrub-A-Dub": 123.18008199092073,
            "Cauldron Filler (Assessment)_4070": 119.41561832900199,
            "accumulated_accuracy_group": 112.90246974276442,
            "success_ratio_Scrub-A-Dub": 110.64496610526557,
            "mean_4070_Chow Time": 110.62247844724897,
            "Mushroom Sorter (Assessment)_4070_mean": 107.6966319622904,
            "Mushroom Sorter (Assessment)_time_to_get_success": 106.8771246279619,
            "mean_4070_Leaf Leader": 103.83267949586362,
            "Cauldron Filler (Assessment)_4070_mean": 99.22703936868302,
            "Mushroom Sorter (Assessment)_success_ratio": 99.05517603403432,
            "mean_incorrect_Pan Balance": 98.86733471907606,
            "mean_incorrect_All Star Sorting": 97.32074891514284,
            "accumulated_failed_attempts": 97.11591790706261,
            "mean_var_action_time_same_assess": 95.61644566169771,
            "mean_action_time_same_assess": 91.63154452965182,
            "var_action_time_Dino Drink": 90.46178468310681,
            "Cart Balancer (Assessment)_success_ratio": 86.15811835269051,
            "success_ratio_Crystals Rule": 83.64422965484482,
            "success_ratio_Pan Balance": 79.63557481931866,
            "success_ratio_Happy Camel": 78.34965842423452,
            "mean_correct_Chow Time": 78.22000212139464,
            "2010": 72.3256965099179,
            "mean_correct_Leaf Leader": 71.29624565767445,
            "last_success_ratio_Leaf Leader": 69.01003665644221,
            "mean_incorrect_Crystals Rule": 66.982529698884,
            "Crystal Caves - Level 3_2000": 66.47479813290703,
            "Chest Sorter (Assessment)_success_ratio": 64.82838393041966,
            "Cauldron Filler (Assessment)_success_ratio": 64.11690409005533,
            "Bird Measurer (Assessment)_accuracy_group": 63.260750022130736,
            "success_ratio_Air Show": 62.98037995735649,
            "last_success_ratio_All Star Sorting": 62.908029013983466,
            "n_last_correct_Dino Dive": 62.58126265916835,
            "Crystal Caves - Level 1_2000": 61.80005092254141,
            "mean_action_time_last_same_assess": 57.13306027208618,
            "last_success_ratio_Happy Camel": 54.279385584567905,
            "All Star Sorting_2025": 51.034850982613534,
            "var_action_time_Scrub-A-Dub": 47.73355493011186,
            "0": 47.66693790412246,
            "var_action_time_last_same_assess": 46.374075432333484,
            "Chest Sorter (Assessment)_4020": 46.21381107607131,
            "memory_decay_coeff_from_last_same_assess": 45.523589868789536,
            "decayed_accuracy_group_last_same_assess": 41.46947521984475,
            "Chest Sorter (Assessment)_time_to_get_success": 41.359028837342336,
            "var_action_time_same_assess": 40.84455559038433,
            "Cauldron Filler (Assessment)_3020_mean": 38.69909940851503,
            "mean_correct_Air Show": 38.4126313471621,
            "Chest Sorter (Assessment)_var_mean_action_time": 36.964529732051595,
            "Cauldron Filler (Assessment)_3020": 36.75017529174511,
            "session_title": 36.51038476386311,
            "time_to_get_success_last_same_assess": 35.40473024594648,
            "Mushroom Sorter (Assessment)_accuracy_group": 34.24551031100709,
            "mean_timte_to_get_success_same_assess": 34.19465347746882,
            "last_success_ratio_Air Show": 31.532576298950517,
            "Chest Sorter (Assessment)_accuracy_group": 29.596852568283065,
            "last_success_ratio_Crystals Rule": 28.346832025007824,
            "decayed_n_failure_last_same_assess": 27.283131096767832,
            "decayed_success_ratio_last_same_assess": 25.351612722074787,
            "n_failure_same_assess": 23.724493058463125,
            "success_ratio_same_assess": 21.451189476251603,
            "world": 19.913625331978984,
            "last_success_ratio_Pan Balance": 18.15573267447926,
            "n_last_correct_Air Show": 15.601677681182627,
            "var_time_to_get_success_same_assess": 12.977210661764548,
            "mean_accuracy_group_same_assess": 11.683994688760139,
            "n_last_correct_Leaf Leader": 10.698760103366293,
            "n_failure_last_same_assess": 5.661345958709717,
            "accuracy_group_last_same_assess": 1.8131420135498046,
            "success_ratio_last_same_assess": 1.212376022338867
        }
    },
    "eval_results": {
        "evals_result": {
            "oof_score": 0.6135282273502246,
            "cv_score": {
                "cv1": {
                    "data_from_test": {
                        "multi_logloss": 0.9661459928878203,
                        "qwk": 0.5735605911431962
                    },
                    "data_from_train": {
                        "multi_logloss": 0.9383401704069557,
                        "qwk": 0.6408232140930834
                    }
                },
                "cv2": {
                    "data_from_test": {
                        "multi_logloss": 0.9638485277757901,
                        "qwk": 0.5700214795678
                    },
                    "data_from_train": {
                        "multi_logloss": 0.9820235461731719,
                        "qwk": 0.6142057675304
                    }
                },
                "cv3": {
                    "data_from_test": {
                        "multi_logloss": 0.9622384077400165,
                        "qwk": 0.5762693375755344
                    },
                    "data_from_train": {
                        "multi_logloss": 0.9637803525513099,
                        "qwk": 0.6019883425703956
                    }
                },
                "cv4": {
                    "data_from_test": {
                        "multi_logloss": 0.9679339017689407,
                        "qwk": 0.5739138977394528
                    },
                    "data_from_train": {
                        "multi_logloss": 1.0140090795709793,
                        "qwk": 0.5770337007479645
                    }
                },
                "cv5": {
                    "data_from_test": {
                        "multi_logloss": 0.9618622482139443,
                        "qwk": 0.5751027869391343
                    },
                    "data_from_train": {
                        "multi_logloss": 0.9898257773636793,
                        "qwk": 0.5879731922834224
                    }
                }
            },
            "n_data": 17690,
            "best_iteration": 799.4,
            "n_features": 119,
            "feature_importance": {
                "mean_target": 98653.56557345521,
                "session_title": 19099.75181612708,
                "success_ratio_last_same_assess": 12854.186848926543,
                "accumulated_accuracy_group": 12712.697919869423,
                "accumulated_acc": 11302.253771574795,
                "mean_accuracy_group_same_assess": 8871.093514938653,
                "decayed_success_ratio_last_same_assess": 8724.67157656122,
                "27253bdc": 7880.302145598829,
                "success_ratio_same_assess": 7066.265165172517,
                "2000": 7011.713715014234,
                "0": 6945.052125096321,
                "mean_timte_to_get_success_same_assess": 6076.695168898627,
                "4070": 5840.903554787301,
                "Crystal Caves - Level 3_2000": 5803.144293764233,
                "3120": 5735.443972356525,
                "world": 4992.076689354237,
                "memory_decay_coeff_from_last_same_assess": 4539.464105217159,
                "mean_action_time_All Star Sorting": 4465.251742241066,
                "Mushroom Sorter (Assessment)_success_ratio": 4432.936352446675,
                "mean_action_time_Happy Camel": 4426.852609944343,
                "mean_correct_Chow Time": 4411.241531455516,
                "mean_incorrect_Pan Balance": 4386.912069518398,
                "memory_decay_coeff_from_last_assess": 4379.5181769285355,
                "decayed_n_failure_last_same_assess": 4185.550299562514,
                "mean_action_time_Chow Time": 4132.730657146638,
                "decayed_accuracy_group_last_same_assess": 4120.494940654736,
                "Cauldron Filler (Assessment)_3020_mean": 4064.2677077129483,
                "3121": 3854.034722917038,
                "Bird Measurer (Assessment)_success_ratio": 3803.3417977005242,
                "mean_action_time_Scrub-A-Dub": 3768.417739537358,
                "duration_mean": 3754.8571450483987,
                "var_action_time_Scrub-A-Dub": 3753.1709006637334,
                "Mushroom Sorter (Assessment)_accuracy_group": 3650.8265775263308,
                "mean_action_time_Dino Drink": 3629.563274602592,
                "Cauldron Filler (Assessment)_success_ratio": 3591.8261372953652,
                "success_ratio_Happy Camel": 3578.056734071672,
                "Cauldron Filler (Assessment)_mean_action_time": 3565.7975458274595,
                "Chest Sorter (Assessment)_mean_var_action_time": 3451.2419406812637,
                "Cart Balancer (Assessment)_success_ratio": 3437.91955383569,
                "n_failure_same_assess": 3421.591069152951,
                "success_ratio_Scrub-A-Dub": 3346.7871815973895,
                "success_ratio_Pan Balance": 3230.1671133860946,
                "4035": 3213.3645263608546,
                "Bird Measurer (Assessment)_mean_var_action_time": 3190.1658937945963,
                "time_to_get_success_last_same_assess": 3171.7642138913275,
                "4020": 3148.870172940008,
                "4030": 3097.0456045154947,
                "mean_action_time_same_assess": 3058.319897731207,
                "Cauldron Filler (Assessment)_mean_var_action_time": 3053.0239743838088,
                "Chest Sorter (Assessment)_mean_action_time": 3028.4493813272566,
                "mean_4070_Chow Time": 2993.5664087712767,
                "Chest Sorter (Assessment)_success_ratio": 2902.919157125056,
                "Chow Time_4070": 2877.843417500658,
                "mean_action_time_last_same_assess": 2684.841321568261,
                "success_ratio_All Star Sorting": 2676.9403255969287,
                "3110": 2604.842258512229,
                "sand_filled_ratio": 2575.7315697833897,
                "launched_ratio": 2536.782163021341,
                "var_action_time_same_assess": 2520.422848622501,
                "mean_incorrect_All Star Sorting": 2408.76021082364,
                "Chest Sorter (Assessment)_4020": 2388.415191453695,
                "success_ratio_Chow Time": 2387.691534204781,
                "var_action_time_last_same_assess": 2360.062934452761,
                "mean_correct_Leaf Leader": 2354.0025386482475,
                "mean_var_action_time_same_assess": 2341.6829000592234,
                "accumulated_failed_attempts": 2287.704876887053,
                "mean_incorrect_Chow Time": 2247.8535875622183,
                "Mushroom Sorter (Assessment)_mean_var_action_time": 2208.022209936194,
                "Sandcastle Builder (Activity)_duration": 2174.1698456309737,
                "last_success_ratio_Pan Balance": 2152.225372218806,
                "mean_incorrect_Scrub-A-Dub": 2138.3349005177615,
                "Mushroom Sorter (Assessment)_time_to_get_success": 2137.473603156209,
                "Mushroom Sorter (Assessment)_mean_action_time": 2071.8508973043877,
                "last_success_ratio_Chow Time": 2038.8982378959656,
                "last_success_ratio_Crystals Rule": 2009.7607406049967,
                "Sandcastle Builder (Activity)_4070": 2007.018051598221,
                "mean_4070_All Star Sorting": 1972.256423805654,
                "Cart Balancer (Assessment)_4070_mean": 1968.2241030529142,
                "Bug Measurer (Activity)_duration": 1958.43572973907,
                "Sandcastle Builder (Activity)_4020": 1957.0748600853142,
                "success_ratio_Dino Dive": 1942.3992007277907,
                "var_time_to_get_success_same_assess": 1902.4074590716511,
                "last_success_ratio_Happy Camel": 1858.866310878843,
                "Cauldron Filler (Assessment)_4070_mean": 1848.0555528026075,
                "4022": 1842.5338126517831,
                "Chest Sorter (Assessment)_time_to_get_success": 1807.6095014691352,
                "last_success_ratio_Leaf Leader": 1781.2465729176997,
                "mean_4070_Leaf Leader": 1762.6783003031276,
                "Mushroom Sorter (Assessment)_4070_mean": 1758.0367727041244,
                "2010": 1741.3675507770852,
                "Mushroom Sorter (Assessment)_4070": 1684.908736858517,
                "last_success_ratio_All Star Sorting": 1674.1027982354165,
                "Bird Measurer (Assessment)_accuracy_group": 1661.3591191351413,
                "success_ratio_Crystals Rule": 1652.8982707943767,
                "Bug Measurer (Activity)_4035": 1625.720931443572,
                "Cauldron Filler (Assessment)_4070": 1623.76920067966,
                "n_launched_False": 1530.2178822532528,
                "count_4070_All Star Sorting": 1485.7745032690466,
                "mean_incorrect_Crystals Rule": 1482.2689676128327,
                "var_action_time_Dino Drink": 1416.201932680607,
                "n_failure_last_same_assess": 1380.092261607945,
                "success_ratio_Air Show": 1379.7622184932231,
                "Cart Balancer (Assessment)_4070": 1379.2679142572451,
                "Mushroom Sorter (Assessment)_var_mean_action_time": 1346.6660042375327,
                "Crystal Caves - Level 2_2000": 1297.398303501308,
                "last_success_ratio_Scrub-A-Dub": 1290.3427695065736,
                "n_last_correct_Leaf Leader": 1285.9184517025947,
                "4090": 1282.11731767077,
                "n_last_correct_Dino Dive": 1259.7960438784212,
                "Chest Sorter (Assessment)_var_mean_action_time": 1112.0175267543643,
                "Bird Measurer (Assessment)_4020": 1060.3185947835445,
                "accuracy_group_last_same_assess": 1030.6256937742232,
                "Cauldron Filler (Assessment)_3020": 986.1862844988704,
                "Crystal Caves - Level 1_2000": 900.7070660308003,
                "Chest Sorter (Assessment)_accuracy_group": 810.811081135273,
                "last_success_ratio_Air Show": 745.0158780455589,
                "All Star Sorting_2025": 713.8483576012775,
                "mean_correct_Air Show": 594.1674171671272,
                "n_last_correct_Air Show": 427.9504064202309
            }
        },
        "valid_score": 0.5794362394544099
    },
    "truncated_eval_mean": 0.5591814111737745,
    "truncated_eval_0.95lower": 0.5407357473384317,
    "truncated_eval_0.95upper": 0.5776270750091174,
    "truncated_eval_std": 0.009222831917671431,
    "truncated_group_eval_mean": 0.5603309796677299,
    "truncated_group_eval_0.95lower": 0.5434704616732069,
    "truncated_group_eval_0.95upper": 0.577191497662253,
    "truncated_group_eval_std": 0.008430258997261499,
    "group_optimized_qwk": 0.6004630528437753
}